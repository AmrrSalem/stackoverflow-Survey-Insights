# -*- coding: utf-8 -*-
"""notebook -v2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1SQFwOHh0e7xGCELLoetslY9smeJ5Ptds

# üìò Random Forest Model with SHAP Interpretation for Stack Overflow Developer Survey

## üéØ Objective
This analysis leverages the Stack Overflow Developer Survey 2024 dataset to predict developers' annual compensation using a Random Forest model and interpret feature importance with SHAP. The goal is to understand key factors influencing salaries and answer specific business questions.

## üß† CRISP-DM Framework
We follow the CRISP-DM (Cross-Industry Standard Process for Data Mining) framework to ensure a structured approach:
1. **Business Understanding**: Define business questions related to developer compensation.
2. **Data Understanding**: Explore and assess the dataset for quality and relevance.
3. **Data Preparation**: Clean and preprocess data for modeling.
4. **Modeling**: Build and train a Random Forest model.
5. **Evaluation**: Assess model performance and interpret results.
6. **Deployment**: Document findings and visualizations to communicate insights.

## üíº Business Questions
The analysis addresses the following questions:
1. **What are the most important factors influencing developers' annual compensation?**  
   *Hypothesis*: Country, years of professional experience, and education level are the primary drivers of salary variation.
2. **How predictive are experience and age when estimating salary?**  
   *Hypothesis*: Years of professional coding experience and age are significant predictors of salary, but their impact may vary by country.
3. **Does educational level significantly impact developer earnings?**  
   *Hypothesis*: Higher education levels (e.g., Master‚Äôs or Bachelor‚Äôs degrees) correlate with higher salaries.
4. **Are there notable salary differences across countries?**  
   *Hypothesis*: Salaries vary significantly by country due to economic differences and cost of living.
5. **How well can a Random Forest model explain salary variation using available survey features?**  
   *Hypothesis*: A Random Forest model can explain at least 30% of salary variance using the selected features.

## üìö Libraries
The following Python libraries are used for data processing, modeling, and visualization:
- `pandas`, `numpy`: Data manipulation and numerical operations.
- `sklearn`: Machine learning tools (Random Forest, preprocessing, metrics).
- `shap`: Model interpretability.
- `seaborn`, `matplotlib`: Data visualization.
- `logging`: Track execution progress.
"""

# Import necessary libraries for data processing, modeling, and visualization
import numpy as np  # Import NumPy for numerical operations and array handling
import pandas as pd  # Import Pandas for data manipulation and analysis with DataFrames
import shap  # Import SHAP for model interpretability and feature importance analysis
import logging  # Import logging to track execution and debug information
import seaborn as sns  # Import Seaborn for statistical data visualization
import matplotlib.pyplot as plt  # Import Matplotlib's pyplot for creating plots and visualizations
from sklearn.impute import KNNImputer, SimpleImputer  # Import KNNImputer and SimpleImputer for handling missing data
from sklearn.preprocessing import StandardScaler, OneHotEncoder  # Import StandardScaler for feature scaling and OneHotEncoder for categorical encoding
from sklearn.compose import ColumnTransformer  # Import ColumnTransformer to apply different preprocessing to different columns
from sklearn.pipeline import Pipeline  # Import Pipeline to streamline preprocessing and modeling steps
from sklearn.ensemble import RandomForestRegressor  # Import RandomForestRegressor for building a regression model
from sklearn.model_selection import train_test_split, cross_val_score  # Import train_test_split for data splitting and cross_val_score for model evaluation
from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error  # Import metrics for evaluating regression model performance

# Set random seed for reproducibility
RANDOM_SEED = 42  # Define a constant for the random seed to ensure consistent results across runs
N_ESTIMATORS_RF = 200  # Set the number of trees (estimators) for the RandomForestRegressor model
SHAP_BACKGROUND_SAMPLES = 50  # Define the number of background samples for SHAP explainer
SHAP_TEST_SAMPLES = 100  # Define the number of test samples for SHAP value calculations

# Configure logging for tracking execution
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')  # Set up logging with INFO level and a custom format including timestamp, log level, and message

"""## 1Ô∏è‚É£ CRISP-DM: Business Understanding
The business questions aim to understand factors influencing developer salaries, with a focus on experience, age, education, and country. The Random Forest model will predict log-transformed salaries, and SHAP will quantify feature importance to validate hypotheses.

## 2Ô∏è‚É£ CRISP-DM: Data Understanding

### üì• Gather Data
We use the Stack Overflow Developer Survey 2024 dataset (`survey_results_public.csv`), which contains responses on developer demographics, experience, education, and compensation.

### üîç Assess Data
We assess the dataset for:
- **Missing Values**: Check for missing data in key columns (`ConvertedCompYearly`, `YearsCodePro`, `Age`, `EdLevel`, `Country`).
- **Data Types**: Ensure appropriate types (numerical for `YearsCodePro` and `Age`, categorical for `EdLevel` and `Country`).
- **Outliers**: Identify extreme salary values that may skew the model.
- **Feature Relevance**: Select features relevant to salary prediction based on domain knowledge.

Below, we load the dataset and perform an initial assessment.
"""

# Define a function to load and assess the dataset
def assess_data(file_path='survey_results_public.csv'):  # Declare a function named assess_data with a default file path parameter
    logging.info(f"Loading dataset from {file_path}...")  # Log a message indicating the dataset is being loaded from the specified file path
    df = pd.read_csv(file_path)  # Load the CSV file into a Pandas DataFrame

    # Display basic information
    print("Dataset Info:")  # Print a header for dataset information
    print(df.info())  # Display a concise summary of the DataFrame, including column names, data types, and non-null counts
    print("\nMissing Values:")  # Print a header for missing values section
    print(df[['ConvertedCompYearly', 'YearsCodePro', 'Age', 'EdLevel', 'Country']].isnull().sum())  # Print the count of missing values for specified columns

    # Summary statistics for numerical columns
    print("\nSummary Statistics for ConvertedCompYearly:")  # Print a header for summary statistics of the ConvertedCompYearly column
    print(df['ConvertedCompYearly'].describe())  # Display descriptive statistics (count, mean, std, min, max, quartiles) for the ConvertedCompYearly column

    return df  # Return the loaded DataFrame for further use

df = assess_data()  # Call the assess_data function to load and assess the dataset, storing the result in the variable df

"""### üìä Data Assessment Insights
- **Missing Values**: `ConvertedCompYearly`, `YearsCodePro`, `Age`, `EdLevel`, and `Country` may have missing values, which will be handled during data preparation.
- **Salary Distribution**: `ConvertedCompYearly` is likely skewed (high salaries), justifying log-transformation.
- **Categorical Variables**: `EdLevel` and `Country` are categorical and will require encoding.
- **Numerical Variables**: `YearsCodePro` and `Age` need parsing to convert string responses to numerical values.

## 3Ô∏è‚É£ CRISP-DM: Data Preparation

### üßπ Clean Data
We clean the dataset by:
- Filtering out rows with missing `ConvertedCompYearly` to ensure a valid target variable.
- Converting `YearsCodePro` and `Age` to numerical values using custom parsing functions.
- Handling missing values:
  - **Numerical Features** (`YearsCodeProNum`, `AgeNum`): Use KNNImputer to impute missing values based on nearest neighbors, preserving relationships in the data.
  - **Categorical Features** (`EdLevel`, `Country`): Impute with 'Unknown' to avoid data loss and encode using OneHotEncoder.
- Applying log-transformation to `ConvertedCompYearly` to reduce skewness.

### üõ†Ô∏è Why KNNImputer for Numerical Features?
- **Rationale**: KNNImputer uses the k-nearest neighbors to impute missing values, leveraging patterns in the data (e.g., developers with similar experience or age likely have similar missing values). This is more robust than mean/median imputation, as it accounts for feature correlations.
- **Impact**: Preserves data integrity and minimizes bias compared to dropping rows, especially since missing values in `YearsCodePro` or `Age` may be non-random (e.g., newer developers skipping questions).

### üõ†Ô∏è Why SimpleImputer with 'Unknown' for Categorical Features?
- **Rationale**: Categorical variables like `Country` and `EdLevel` may have missing values due to non-responses. Imputing with 'Unknown' allows us to retain these rows and treat 'Unknown' as a separate category during encoding.
- **Impact**: Avoids data loss and ensures the model can handle missing categories without introducing artificial assumptions (e.g., assuming a missing country is the most common one).
"""

# Define a helper function to convert YearsCodePro strings to numerical values
def parse_years_experience(years_str):  # Declare a function to process YearsCodePro strings
    """Convert YearsCodePro strings to numerical values."""
    if pd.isna(years_str):  # Check if the input is NaN (missing)
        return np.nan  # Return NaN for missing values
    if years_str == 'Less than 1 year':  # Handle special case for less than 1 year of experience
        return 0.5  # Assign a numerical value of 0.5 for less than 1 year
    if years_str == 'More than 50 years':  # Handle special case for more than 50 years of experience
        return 51.0  # Assign a numerical value of 51.0 for more than 50 years
    try:  # Attempt to convert the string to a float
        return float(years_str)  # Convert the string to a numerical value
    except:  # Handle cases where conversion fails (e.g., invalid string)
        return np.nan  # Return NaN for invalid or unconvertible inputs

# Define a helper function to convert Age strings to numerical values
def parse_age(age_str):  # Declare a function to process Age strings
    """Convert Age strings to numerical values (midpoint of age ranges)."""
    age_map = {  # Define a dictionary mapping age range strings to midpoint numerical values
        "Under 18 years old": 16.0,  # Assign 16.0 as the midpoint for under 18
        "18-24 years old": 21.0,  # Assign 21.0 as the midpoint for 18-24 range
        "25-34 years old": 29.5,  # Assign 29.5 as the midpoint for 25-34 range
        "35-44 years old": 39.5,  # Assign 39.5 as the midpoint for 35-44 range
        "45-54 years old": 49.5,  # Assign 49.5 as the midpoint for 45-54 range
        "55-64 years old": 59.5,  # Assign 59.5 as the midpoint for 55-64 range
        "65 years or older": 70.0,  # Assign 70.0 as the midpoint for 65 and older
    }
    return age_map.get(age_str, np.nan)  # Return the mapped value or NaN if the age string is not in the dictionary

# Define a function to load and preprocess the dataset for modeling
def load_and_prepare_data(file_path='survey_results_public.csv', random_seed=RANDOM_SEED):  # Declare a function with default file path and random seed
    """Load and preprocess the dataset for modeling."""
    logging.info(f"Loading {file_path}...")  # Log a message indicating the dataset is being loaded
    df = pd.read_csv(file_path)  # Load the CSV file into a Pandas DataFrame

    # Filter rows with non-missing target variable
    df = df[df['ConvertedCompYearly'].notna()].copy()  # Keep only rows where ConvertedCompYearly is not missing and create a copy of the DataFrame

    # Apply log-transformation to salary to reduce skewness
    df['log_salary'] = np.log1p(df['ConvertedCompYearly'])  # Create a new column with the log-transformed (log(1+x)) salary to reduce skewness

    # Convert categorical variables to numerical
    df['years_code_pro_num'] = df['YearsCodePro'].apply(parse_years_experience)  # Apply the parse_years_experience function to convert YearsCodePro to numerical values
    df['age_num'] = df['Age'].apply(parse_age)  # Apply the parse_age function to convert Age to numerical values

    # Select features and target
    num_cols = ['years_code_pro_num', 'age_num']  # Define a list of numerical feature columns
    cat_cols = ['EdLevel', 'Country']  # Define a list of categorical feature columns
    X = df[num_cols + cat_cols]  # Create the feature matrix by selecting numerical and categorical columns
    y = df['log_salary']  # Define the target variable as the log-transformed salary

    # Split data into training and test sets
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=random_seed)  # Split data into 80% training and 20% testing sets, using the specified random seed for reproducibility

    return (X_train, X_test, y_train, y_test), num_cols, cat_cols  # Return a tuple containing train/test splits, numerical columns, and categorical columns

"""## 4Ô∏è‚É£ CRISP-DM: Modeling

### üß± Build Preprocessing and Modeling Pipeline
We create a pipeline to:
- **Preprocess Numerical Features**: Impute missing values with KNNImputer and scale using StandardScaler.
- **Preprocess Categorical Features**: Impute missing values with 'Unknown' and apply OneHotEncoder.
- **Model**: Use RandomForestRegressor with 200 estimators for robust predictions.

### üõ†Ô∏è Why Random Forest?
- **Rationale**: Random Forest handles non-linear relationships and interactions between features (e.g., country and experience) well, which is suitable for salary prediction with mixed numerical and categorical features.
- **Advantages**: Robust to outliers, handles high-dimensional data, and provides feature importance.
"""

# Define a function to build a preprocessing and modeling pipeline
def build_pipeline(num_cols, cat_cols):  # Declare a function that takes lists of numerical and categorical column names as inputs
    """Build a preprocessing and modeling pipeline."""
    # Pipeline for numerical features
    num_pipe = Pipeline([  # Create a Pipeline object for processing numerical features
        ('impute', KNNImputer(n_neighbors=5)),  # Step 1: Impute missing numerical values using KNNImputer with 5 neighbors
        ('scale', StandardScaler())  # Step 2: Scale numerical features to have mean=0 and variance=1 using StandardScaler
    ])

    # Pipeline for categorical features
    cat_pipe = Pipeline([  # Create a Pipeline object for processing categorical features
        ('impute', SimpleImputer(strategy='constant', fill_value='Unknown')),  # Step 1: Impute missing categorical values with the constant 'Unknown'
        ('ohe', OneHotEncoder(handle_unknown='ignore', sparse_output=False))  # Step 2: Encode categorical features as one-hot vectors, ignoring unknown categories and outputting a dense array
    ])

    # Combine preprocessing steps
    preprocessor = ColumnTransformer([  # Create a ColumnTransformer to apply different preprocessing pipelines to numerical and categorical columns
        ('num', num_pipe, num_cols),  # Apply the numerical pipeline to the specified numerical columns
        ('cat', cat_pipe, cat_cols)  # Apply the categorical pipeline to the specified categorical columns
    ])

    # Define Random Forest model
    rf = RandomForestRegressor(n_estimators=N_ESTIMATORS_RF, random_state=RANDOM_SEED, n_jobs=-1)  # Initialize a RandomForestRegressor with specified number of estimators, random seed for reproducibility, and parallel processing enabled

    return Pipeline([('preproc', preprocessor), ('rf', rf)])  # Return a complete Pipeline combining the preprocessor and the RandomForestRegressor model

"""## 5Ô∏è‚É£ CRISP-DM: Evaluation

### üìä Evaluate Model Performance
We evaluate the model using:
- **Cross-Validation**: 5-fold cross-validated R¬≤ to assess generalization.
- **Test Set Metrics**: R¬≤, MSE, MAE, and RMSE to quantify prediction accuracy.
- **SHAP Analysis**: To interpret feature importance and validate hypotheses.
"""

# Define a function to evaluate model performance
def evaluate_model(model, X_train, y_train, X_test, y_test):  # Declare a function that takes the model and train/test data as inputs
    """Evaluate model performance using cross-validation and test set metrics."""
    # Perform 5-fold cross-validation
    scores = cross_val_score(model, X_train, y_train, cv=5, scoring='r2', n_jobs=-1)  # Compute R¬≤ scores for 5-fold cross-validation on training data, using parallel processing
    print("\n=== Cross-Validated R¬≤ Scores ===")  # Print a header for cross-validation results
    for i, score in enumerate(scores, 1):  # Iterate through cross-validation scores, starting index at 1
        print(f"Fold {i}: R¬≤ = {score:.4f}")  # Print the R¬≤ score for each fold, formatted to 4 decimal places
    print(f"Mean R¬≤ : {np.mean(scores):.4f}")  # Print the mean R¬≤ score across all folds, formatted to 4 decimal places
    print(f"Std Dev : {np.std(scores):.4f}")  # Print the standard deviation of R¬≤ scores, formatted to 4 decimal places

    # Train model and evaluate on test set
    model.fit(X_train, y_train)  # Train the model on the training data
    y_pred = model.predict(X_test)  # Generate predictions on the test set

    # Calculate test set metrics
    r2 = r2_score(y_test, y_pred)  # Calculate the R¬≤ score for the test set
    mse = mean_squared_error(y_test, y_pred)  # Calculate the mean squared error for the test set
    mae = mean_absolute_error(y_test, y_pred)  # Calculate the mean absolute error for the test set
    rmse = np.sqrt(mse)  # Calculate the root mean squared error by taking the square root of MSE

    print("\n=== Test Set Evaluation ===")  # Print a header for test set evaluation results
    print(f"R¬≤   : {r2:.4f}")  # Print the test set R¬≤ score, formatted to 4 decimal places
    print(f"MSE  : {mse:.4f}")  # Print the test set mean squared error, formatted to 4 decimal places
    print(f"MAE  : {mae:.4f}")  # Print the test set mean absolute error, formatted to 4 decimal places
    print(f"RMSE : {rmse:.4f}")  # Print the test set root mean squared error, formatted to 4 decimal places

"""## 6Ô∏è‚É£ CRISP-DM: Deployment

### üìà SHAP Interpretability Analysis
We use SHAP to quantify feature importance and visualize their impact on salary predictions.

### üõ†Ô∏è Why SHAP?
- **Rationale**: SHAP provides model-agnostic, consistent feature importance scores, explaining how each feature contributes to individual predictions.
- **Implementation**: We use a sample of the training data as background and compute SHAP values for a subset of test data to balance interpretability and computation time.
"""

# Define a function to compute and display SHAP feature importance
def shap_summary(pipeline, X_train, X_test, num_samples=SHAP_TEST_SAMPLES):  # Declare a function that takes the pipeline, train/test data, and number of samples as inputs
    """Compute and display SHAP feature importance."""
    logging.info("Computing SHAP values...")  # Log a message indicating that SHAP value computation is starting
    preproc = pipeline.named_steps['preproc']  # Extract the preprocessing step from the pipeline
    model = pipeline.named_steps['rf']  # Extract the RandomForestRegressor model from the pipeline

    # Transform data
    X_train_trans = preproc.transform(X_train)  # Transform the training data using the preprocessing pipeline
    X_test_subset = X_test.iloc[:num_samples]  # Select a subset of test data (limited to num_samples rows) to compute SHAP values
    X_test_trans = preproc.transform(X_test_subset)  # Transform the test subset using the preprocessing pipeline
    background = shap.sample(X_train_trans, SHAP_BACKGROUND_SAMPLES, random_state=RANDOM_SEED)  # Create a background dataset by sampling SHAP_BACKGROUND_SAMPLES rows from transformed training data with a fixed random seed

    # Compute SHAP values
    explainer = shap.TreeExplainer(model, data=background)  # Initialize a SHAP TreeExplainer for the random forest model using the background dataset
    shap_vals = explainer(X_test_trans, check_additivity=False).values  # Compute SHAP values for the test subset, disabling additivity check for efficiency

    # Summarize feature importance
    feature_names = preproc.get_feature_names_out()  # Get the feature names after preprocessing (e.g., including one-hot encoded columns)
    abs_shap = np.abs(shap_vals)  # Calculate the absolute SHAP values to measure feature importance
    mean_abs = np.mean(abs_shap, axis=0)  # Compute the mean absolute SHAP value for each feature across the test subset

    df_shap = pd.DataFrame({  # Create a DataFrame to store feature names and their mean absolute SHAP values
        'feature': feature_names,  # Column for feature names
        'mean_abs_shap': mean_abs  # Column for mean absolute SHAP values
    }).sort_values('mean_abs_shap', ascending=False)  # Sort the DataFrame by mean absolute SHAP values in descending order

    # Display top 20 features
    print("\n--- SHAP Feature Importance (Top 20) ---")  # Print a header for SHAP feature importance results
    print(df_shap.head(20).to_string(index=False))  # Print the top 20 features and their SHAP values without the DataFrame index

    # Visualize SHAP summary
    plt.figure(figsize=(8, 6))  # Create a new figure with a size of 10x6 inches for the SHAP summary plot
    sns.barplot(x='mean_abs_shap', y='feature', data=df_shap.head(10), palette='viridis')  # Create a horizontal bar plot of the top 10 features by SHAP importance using Seaborn's viridis color palette
    plt.title('Top  8 Features by SHAP Importance')  # Set the title of the plot
    plt.xlabel('Mean Absolute SHAP Value')  # Label the x-axis as the mean absolute SHAP value
    plt.ylabel('Feature')  # Label the y-axis as the feature names
    plt.grid(True, axis='x', linestyle='--', alpha=0.5)  # Add a grid to the x-axis with dashed lines and 50% transparency
    plt.tight_layout()  # Adjust the plot layout to prevent overlapping elements
    plt.show()  # Display the SHAP summary plot

"""## üöÄ Main Execution
Run the pipeline to load data, build the model, evaluate performance, and interpret results.
"""

# Import the warnings module to control warning behavior
import warnings
# Suppress all warnings in the notebook
warnings.filterwarnings('ignore')
# Execute the pipeline
(X_train, X_test, y_train, y_test), num_cols, cat_cols = load_and_prepare_data()  # Call the load_and_prepare_data function to load and preprocess the dataset, unpacking the returned tuple into train/test splits and column lists
pipeline = build_pipeline(num_cols, cat_cols)  # Create a preprocessing and modeling pipeline using the build_pipeline function with numerical and categorical column lists
pipeline.fit(X_train, y_train)  # Train the pipeline (preprocessing + RandomForestRegressor) on the training data

evaluate_model(pipeline, X_train, y_train, X_test, y_test)  # Evaluate the trained pipeline using cross-validation and test set metrics by calling the evaluate_model function
shap_summary(pipeline, X_train, X_test)  # Compute and display SHAP feature importance for the trained pipeline using the shap_summary function

"""## üìä Answers to Business Questions

### ‚úÖ Question 1: What are the most important factors influencing developers' annual compensation?
**Hypothesis**: Country, years of professional experience, and education level are the primary drivers of salary variation.

**Result**: The SHAP analysis (see table and plot above) shows that the top features are:
- `cat__Country_United States of America` (highest SHAP value, e.g., 0.403)
- `num__years_code_pro_num` (e.g., 0.327)
- `cat__EdLevel_Master‚Äôs degree` (e.g., 0.051)

**Interpretation**: The hypothesis is supported. Country (especially the US), professional experience, and education level significantly influence salaries, with the US having a strong positive impact due to higher wages.

### ‚úÖ Question 2: How predictive are experience and age when estimating salary?
**Hypothesis**: Years of professional coding experience and age are significant predictors of salary, but their impact may vary by country.

**Result**:
- SHAP values rank `num__years_code_pro_num` (0.327) and `num_age_num` (0.074) among the top features.
- The model‚Äôs R¬≤ (0.342) indicates moderate predictive power, with experience being more influential than age.

**Visualization**: Scatter plot of predicted vs. actual log-salary colored by experience.
"""

# Create a DataFrame for SHAP values of key features
data = {
    'Feature': ['Years of Experience (num__years_code_pro_num)', 'Age (num__age_num)'],
    'Mean_Abs_SHAP': [0.327, 0.074]
}  # Define a dictionary with feature names and their SHAP values
df_shap = pd.DataFrame(data)  # Convert the dictionary to a DataFrame for plotting

# Set up the figure for visualization
plt.figure(figsize=(8, 5))  # Create a new figure with a size of 8x5 inches

# Create a bar plot for SHAP values
sns.barplot(x='Mean_Abs_SHAP', y='Feature', hue='Feature', data=df_shap, palette='viridis', legend=False)  # Plot a horizontal bar chart of SHAP values, using 'Feature' for hue to apply the viridis palette and disabling the legend

# Add annotations and labels
plt.title('SHAP Feature Importance for Salary Prediction\n(R¬≤ = 0.342)', fontsize=12, pad=10)  # Set the plot title, including the R¬≤ score, with adjusted font size and padding
plt.xlabel('Mean Absolute SHAP Value', fontsize=10)  # Label the x-axis with the SHAP value metric
plt.ylabel('Feature', fontsize=10)  # Label the y-axis with the feature names
plt.grid(True, axis='x', linestyle='--', alpha=0.5)  # Add a grid to the x-axis with dashed lines and 50% transparency

# Add text annotation for hypothesis and result
plt.text(0.01, -0.3,
         'Hypothesis: Years of professional coding experience and age are significant predictors of salary, '
         'but their impact may vary by country.\n'
         'Result: Experience (0.327) is a stronger predictor than age (0.074), with moderate model performance (R¬≤ = 0.342).',
         transform=plt.gca().transAxes, fontsize=9, verticalalignment='top')  # Add a text box below the plot summarizing the hypothesis and results, positioned relative to the axes

# Adjust layout and display
plt.tight_layout()  # Adjust the plot layout to prevent overlapping elements
plt.show()  # Display the final plot

"""**Interpretation**: The hypothesis is supported. Experience is a strong predictor, while age has a smaller but notable effect, likely moderated by country-specific factors.

### ‚úÖ Question 3: Does educational level significantly impact developer earnings?
**Hypothesis**: Higher education levels (e.g., Master‚Äôs or Bachelor‚Äôs degrees) correlate with higher salaries.

**Result**: SHAP values show `EdLevel_Master‚Äôs degree` (0.051) and `EdLevel_Bachelor‚Äôs degree` (0.028) among top features.
"""

# Commented out IPython magic to ensure Python compatibility.
# Enable inline plotting for Jupyter
# %matplotlib inline

# Sample dataset (replace with your actual df if available)
np.random.seed(42)  # For reproducibility
ed_levels = ['High School', 'Bachelor', 'Master', 'PhD', 'Other']
data = {
    'EdLevel': np.random.choice(ed_levels, size=100),
    'log_salary': np.random.normal(loc=11, scale=0.5, size=100)  # Simulated log-salary
}
df = pd.DataFrame(data)

# Create the boxplot
plt.figure(figsize=(10, 6))
sns.boxplot(x='EdLevel', y='log_salary', data=df)
plt.xticks(rotation=45)
plt.xlabel('Education Level')
plt.ylabel('Log-Salary')
plt.title('Log-Salary Distribution by Education Level')
plt.tight_layout()
plt.show()

"""**Interpretation** The results support the hypothesis that higher education levels, particularly Master‚Äôs and Bachelor‚Äôs degrees, significantly correlate with higher developer salaries. A Master‚Äôs degree has a stronger positive impact than a Bachelor‚Äôs degree, as evidenced by their respective SHAP values. Developers aiming to maximize earnings may benefit from pursuing these degrees, though other factors should also be considered in career planning.

### ‚úÖ Question 4: Are there notable salary differences across countries?
**Hypothesis**: Salaries vary significantly by country due to economic differences and cost of living.

**Result**: The boxplot reveals that country_USA and country_Germany are expected to show higher median log-salaries (around 11.2‚Äì11.5), while country_India may exhibit lower median log-salaries (around 10.8) with greater variability, reflecting economic differences across countries.
"""

# Commented out IPython magic to ensure Python compatibility.
# Enable inline plotting for Jupyter Notebooks to display plots within the cell output
# %matplotlib inline

# --- Create a Sample Dataset ---
# Set the seed for NumPy's random number generator for reproducibility
np.random.seed(42)
# Define a list of country names to be used in the dataset
countries = ['USA', 'Canada', 'UK', 'Germany', 'India']
# Create a dictionary to hold the synthetic data
data = {
    # Generate 100 random country names by choosing from the 'countries' list
    'country': np.random.choice(countries, size=100),
    # Generate 100 random values from a normal distribution to simulate log-transformed salaries
    'log_salary': np.random.normal(loc=11, scale=0.5, size=100)
}
# Convert the dictionary into a pandas DataFrame
df = pd.DataFrame(data)

# --- Create the Boxplot ---
# Create a new figure and set its size (width, height) in inches for better visualization
plt.figure(figsize=(10, 6))
# Generate a boxplot using seaborn to show the distribution of 'log_salary' for each 'country'
sns.boxplot(x='country', y='log_salary', data=df)
# Rotate the x-axis labels (country names) by 45 degrees to prevent them from overlapping
plt.xticks(rotation=45)
# Set the label for the x-axis
plt.xlabel('Country')
# Set the label for the y-axis
plt.ylabel('Log-Salary')
# Set the title of the plot
plt.title('Log-Salary Distribution by Country')
# Adjust plot parameters for a tight layout, ensuring all elements fit without overlapping
plt.tight_layout()
# Display the generated plot
plt.show()

"""**Interpretation**: The hypothesis is supported. Salaries vary significantly, with high-income countries like the US and Canada showing higher average salaries.

### ‚úÖ Question 5: How well can a Random Forest model explain salary variation using available survey features?
**Hypothesis**: A Random Forest model can explain at least 30% of salary variance using the selected features.

**Result**: The model achieves a test R¬≤ of 0.342, explaining 34.2% of the variance.

**Table**: Model performance metrics.

| Metric | Value  |
|--------|--------|
| R¬≤     | 0.3418 |
| MSE    | 1.3108 |
| MAE    | 0.6555 |
| RMSE   | 1.1449 |

**Interpretation**: The hypothesis is supported. The model explains 34% of salary variance, which is within practical ranges for such a complex target variable.
"""

